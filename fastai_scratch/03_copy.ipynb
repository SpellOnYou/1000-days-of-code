{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_copy.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR7WdFvw8XPN",
        "colab_type": "text"
      },
      "source": [
        "- 01_matmul\n",
        "- 02_fully_connected\n",
        "- 02a_why_sqrt5\n",
        "- 02b_initialization\n",
        "- 03_minibatch_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ios0-s_4_ZwU",
        "colab_type": "text"
      },
      "source": [
        "Table of contents\n",
        "1. Initial Setup\n",
        "2. Basic training Loop\n",
        "3. Using parameters and optim\n",
        "4. Dataset and DataLoader\n",
        "5. Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxTB-ysp_jun",
        "colab_type": "text"
      },
      "source": [
        "# 1. Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be1B6I_hCh1c",
        "colab_type": "text"
      },
      "source": [
        "## Data\n",
        "\n",
        "### Fastai for Colab env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMCFq0PZ8tOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2aa664ab-65f0-4965-e06c-98a29adfc823"
      },
      "source": [
        "!git clone http://github.com/fastai/course-v3.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'course-v3'...\n",
            "warning: redirecting to https://github.com/fastai/course-v3.git/\n",
            "remote: Enumerating objects: 5498, done.\u001b[K\n",
            "remote: Total 5498 (delta 0), reused 0 (delta 0), pack-reused 5498\u001b[K\n",
            "Receiving objects: 100% (5498/5498), 257.94 MiB | 34.24 MiB/s, done.\n",
            "Resolving deltas: 100% (2992/2992), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3cSi27X88l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa748adf-bec8-48f3-c291-ab37acfd9cf1"
      },
      "source": [
        "%cd course-v3/nbs/dl2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/course-v3/nbs/dl2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FacmFUWm9E-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from exp.nb_02 import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAdev1qg-LSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "61f6b9b4-06f2-4ae5-cf72-d42eef47323c"
      },
      "source": [
        "!cat exp/nb_02.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#################################################\n",
            "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n",
            "#################################################\n",
            "# file to edit: dev_nb/02_fully_connected.ipynb\n",
            "\n",
            "from exp.nb_01 import *\n",
            "\n",
            "def get_data():\n",
            "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
            "    with gzip.open(path, 'rb') as f:\n",
            "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
            "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
            "\n",
            "def normalize(x, m, s): return (x-m)/s\n",
            "\n",
            "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n",
            "\n",
            "from torch.nn import init\n",
            "\n",
            "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()\n",
            "\n",
            "from torch import nn"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5tAEA4_9NKW",
        "colab_type": "text"
      },
      "source": [
        "### import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTgE-wJ49UaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72d574b6-23a8-4483-b284-fbe45b395980"
      },
      "source": [
        "train_x, train_y, valid_x, valid_y = get_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoL0CV2v9gLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03bf68f3-2efd-49f7-9179-923b241d60d9"
      },
      "source": [
        "train_x.shape, train_x.type()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 784]), 'torch.FloatTensor')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8VUDJEG2qWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m, n_in = train_x.shape\n",
        "nh = 70 # on perpose changed little bit bigger\n",
        "n_out = train_y.max().item()+1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWzQQ9W49hwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd10c5f2-729c-482f-f848-5faac1e4e199"
      },
      "source": [
        "# n_in, nh, n_out = train_x.shape[1], 32, train_y.max().item()+1; n_in, nh, n_out"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 32, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCU0bL8XA76r",
        "colab_type": "text"
      },
      "source": [
        "[^1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EuhUclG2-47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a06bd6c3-8c4a-48c6-aa16-31205e31e8d9"
      },
      "source": [
        "n_in, nh, n_out"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 70, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euyGKZhK94Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x\n",
        "    # def forward(self, x, y):\n",
        "    #     for l in self.layers: x = l(x)\n",
        "    #     return(self.loss(x, y))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2WPI509B_-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(n_in, nh, n_out)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPwo2EesCEsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = model(train_x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJQReyi-CNVm",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGhM0NZrCsfI",
        "colab_type": "text"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyX4TB0YCzpZ",
        "colab_type": "text"
      },
      "source": [
        "* formula of softmax : $f(x) = \\frac{exp(x)}{\\sum exp(x_i)}$\n",
        "* We need softmax at last layer since we have to map it to the probabilistic space\n",
        "* code of softmax is below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJcewmjDhyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x): return x.exp() / x.exp().sum(-1, keepdim=True)\n",
        "# def softmax(x): return x.exp() / x.exp().sum()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NnUt5FGHAaE",
        "colab_type": "text"
      },
      "source": [
        "[^2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7RiaE7kHZuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70edb465-c628-46c5-ff26-806cfdc26f1a"
      },
      "source": [
        "p = softmax(y_hat); p[0].sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BwNmdysHg7A",
        "colab_type": "text"
      },
      "source": [
        "- I need *log* of softmax because we will use cross-entropy which has form of $H(X, q) = H(X) + D(p|q) = - \\sum_{x} p(x)\\  log\\ q(x)$ [^3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr8RQd3ZRppI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return (x.exp() / x.exp().sum(-1, keepdim=True)).log()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0usabhbXdAvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = log_softmax(y_hat)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLksrlDQS3ue",
        "colab_type": "text"
      },
      "source": [
        "### Cross Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNFW_jxyS7Ek",
        "colab_type": "text"
      },
      "source": [
        "- see the footnote 3 regarding further information of cross entropy\n",
        "- One possible reason is because an information theory is based on descrete and determinate value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7tREkCuU65w",
        "colab_type": "text"
      },
      "source": [
        "### Negative log likelihood function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94nPlA0oXJbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(x, y): return -x[range(x.shape[0]), y].mean() #x: prediction, y:target "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcKHlflJX7p3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04c80731-bbbf-4c7e-d009-763d1dc28586"
      },
      "source": [
        "nll(y_hat, train_y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0208, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFJuF2ibXuIq",
        "colab_type": "text"
      },
      "source": [
        "- Negative value is related to entropy, roughly variable which is rare is meaningful [^4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-8dPvdkcKLb",
        "colab_type": "text"
      },
      "source": [
        "### LogSumExp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2GCqf3cLjN",
        "colab_type": "text"
      },
      "source": [
        "- what is logsumexp?\n",
        "\n",
        "$log \\frac{e^{x}}{\\sum_{i} e^{x_i}} \\rightarrow \\log e^{x} - \\log \\sum_{i} e^{x_i} \\rightarrow x - \\log \\sum_{i} e^{x_i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0jIz5RcQAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkBVKsKqpcvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fn = lambda x: x - x.sum(-1, keepdim=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbj1y3lYdKBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "531fcd11-3652-459b-b2ec-8307394a3193"
      },
      "source": [
        "test_near(log_softmax(y_hat), fn(y_hat)) #[^5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fed52eaff586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[^5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest_near\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: near:\ntensor([[-2.2890, -2.3351, -2.1663,  ..., -2.4132, -2.3092, -2.4040],\n        [-2.3235, -2.3194, -2.1267,  ..., -2.2712, -2.3718, -2.4507],\n        [-2.3035, -2.2982, -2.2372,  ..., -2.4181, -2.3473, -2.4329],\n        ...,\n        [-2.1668, -2.3506, -2.2429,  ..., -2.3973, -2.2534, -2.4544],\n        [-2.1334, -2.3439, -2.2947,  ..., -2.3556, -2.2732, -2.4194],\n        [-2.1755, -2.3264, -2.1967,  ..., -2.4686, -2.2711, -2.4828]],\n       grad_fn=<SubBackward0>)\ntensor([[-0.4101, -0.4562, -0.2874,  ..., -0.5343, -0.4303, -0.5252],\n        [-0.1104, -0.1063,  0.0864,  ..., -0.0581, -0.1587, -0.2376],\n        [ 0.0468,  0.0522,  0.1132,  ..., -0.0677,  0.0030, -0.0826],\n        ...,\n        [-0.1510, -0.3348, -0.2272,  ..., -0.3816, -0.2377, -0.4387],\n        [-0.3760, -0.5865, -0.5373,  ..., -0.5982, -0.5158, -0.6619],\n        [-0.1916, -0.3424, -0.2127,  ..., -0.4847, -0.2872, -0.4989]],\n       grad_fn=<SubBackward0>)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTbuDvuWdh9g",
        "colab_type": "text"
      },
      "source": [
        "# 2. Basic Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbRnQ8ildlOr",
        "colab_type": "text"
      },
      "source": [
        "### 1.\n",
        " Write down the procedure the training loop repeats (4 steps)\n",
        "\n",
        "1. make a prediction\n",
        "2. get loss from output\n",
        "3. gradient from output\n",
        "4. update gradient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adPOGFtbxkuH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmWDiw0WmEc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(hat, trg): return (hat.max(-1).indices == trg).sum() / float(hat.shape[0]) # made f1 score, but had to see if this is right."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sltGYfOrh6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "496850c7-e7d5-4ff7-dd75-a3cda6e33261"
      },
      "source": [
        "accuracy(y_hat, train_y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1112)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwLjVknizXdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7T5iw5rzpVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6eb527c-21d4-4510-ad7e-d0c98297174b"
      },
      "source": [
        "acc(y_hat, train_y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1112)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4l_ifJgrr7U",
        "colab_type": "text"
      },
      "source": [
        "3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPhRWFbeAm3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 64"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_65Hf8GOAX85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3dfe1ec-95d1-4399-f287-629504d2d389"
      },
      "source": [
        "xb, yb = train_x[0:bs], train_y[0:bs]\n",
        "accuracy(model(xb), yb)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1094)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0XFnDzNAjOV",
        "colab_type": "text"
      },
      "source": [
        "### 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyAntVEVrw80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "loss_fun = F.cross_entropy\n",
        "epochs = 1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JBbL2EYtf6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5R_jNGrwNSn",
        "colab_type": "text"
      },
      "source": [
        "When I have no attribute checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bJF9lE-vqyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "69fa5aab-32fb-4c94-f123-d446a640318e"
      },
      "source": [
        "[l.weight.grad for l in model.layers]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-84a4dd9c3498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-84a4dd9c3498>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ReLU' object has no attribute 'weight'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWhU_93DwSfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f25c9cf-66d2-4414-8c41-a353e9a356aa"
      },
      "source": [
        "[l.weight.grad for l in model.layers if hasattr(l, 'weight')]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-tHFFLZwW-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01c86080-4afb-4811-c7f0-5ebec75040c8"
      },
      "source": [
        "model = Model(n_in, nh, n_out)\n",
        "yb_hat = model(xb)\n",
        "loss = loss_fun(yb_hat, yb)\n",
        "loss.backward()\n",
        "loss, accuracy(model(xb), yb)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.3024, grad_fn=<NllLossBackward>), tensor(0.1094))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-rba1CswopP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[l.weight.grad for l in m.layers if hasattr(l, 'weight')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue4e2y2R_D9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(m, **kargs):\n",
        "    for epoch in range(epochs):\n",
        "        # for i in range((train_x.shape[0] // bs)+1):\n",
        "        for i in range((train_x.shape[0]-1)//bs +1):\n",
        "            # [^10]\n",
        "            xb, yb = train_x[(bs*i):(bs*(i+1))], train_y[(bs*i):(bs*(i+1))]\n",
        "            loss = loss_fun(m(xb), yb)\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for l in m.layers: # [^8]\n",
        "                    if hasattr(l, 'weight'): #[^6]\n",
        "                        l.weight -= l.weight.grad * lr\n",
        "                        l.bias -= l.bias.grad * lr\n",
        "                        l.weight.grad.zero_() #[^7]\n",
        "                        l.bias.grad.zero_()\n",
        "    return m"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbctQSPP_Zib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m1 = fit(Model(n_in, 50, n_out))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI767mS0z4t2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "641dda5c-5eeb-4247-bc17-5e301382f988"
      },
      "source": [
        "loss_fun(m1(xb), yb), accuracy(m1(xb), yb)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1438, grad_fn=<NllLossBackward>), tensor(0.9531))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCf-IC-o4i8i",
        "colab_type": "text"
      },
      "source": [
        "[^9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB9w0mADRmwP",
        "colab_type": "text"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKh7TcqJRQ0-",
        "colab_type": "text"
      },
      "source": [
        "[^1]: I don't have to define parameters no more, but obviously at first I tried to iniailized Model with `w1, b1, ....`, meaning I didn't practice enough the previous part, part of the torch nn, where I get parameters\n",
        "\n",
        "[^2]: be cautious since `train_x.sum(-1)` will squeeze the rank, so that you need arg `keepdim:bool`, false as default\n",
        "\n",
        "[^3]: see *eq (2.46)*, Foundations of Natural Language Processing, Christopher D. Manning and Hinrich Sch√ºtze\n",
        "\n",
        "[^4]: Should check for `cross-entropy $\\approx$ softmax of negative likelihood`\n",
        "\n",
        "[^5]: why I can't make it like `fn`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr9R50W2cXUc",
        "colab_type": "text"
      },
      "source": [
        "[^6]: We need this since not 'all' the layers have weight, in this care `ReLU`\n",
        "\n",
        "[^7]: Still can't get why I should do this\n",
        "\n",
        "[^8]: Basically, this is model instance which comes from `Model()` inheriting `nn.Module`.</br> `layers` is attribute of that instance, not a method!\n",
        "\n",
        "[^9]: (solved) I cant' get any difference between jeremy's and mine, I just changed node size to 70 (50 at Jeremy) But, does that make this much diffference????????<br/> >>> I did a mistake which take gradients out from gradient!!!!!!!you should take out from variable, not gradients... I wasted almost an hour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su7gX5j8-UDd",
        "colab_type": "text"
      },
      "source": [
        "[^10]: `cliping batchsize` part is somewhat different from jeremy's"
      ]
    }
  ]
}